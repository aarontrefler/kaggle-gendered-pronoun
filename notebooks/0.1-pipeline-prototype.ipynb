{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aarontrefler_temp2/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_path = \"/Users/aarontrefler_temp2/Documents/My_Documents/Kaggle/kaggle-gendered-pronoun/\"\n",
    "sys.path.insert(0, proj_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert.modeling\n",
    "import bert.extract_features\n",
    "import bert.tokenization\n",
    "\n",
    "import src.utils as utils\n",
    "import src.data.data_utils as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = proj_path + \"models/\"\n",
    "bert_dir = proj_path + \"bert/\"\n",
    "data_interim_dir = proj_path + \"data/interim/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(proj_path + \"data/raw/gap-development.tsv\", sep='\\t')\n",
    "valid_df = pd.read_csv(proj_path + \"data/raw/gap-validation.tsv\", sep='\\t')\n",
    "test_df = pd.read_csv(proj_path + \"data/raw/gap-test.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development-1</td>\n",
       "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
       "      <td>her</td>\n",
       "      <td>274</td>\n",
       "      <td>Cheryl Cassidy</td>\n",
       "      <td>191</td>\n",
       "      <td>True</td>\n",
       "      <td>Pauline</td>\n",
       "      <td>207</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/List_of_Teachers_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                               Text Pronoun  \\\n",
       "0  development-1  Zoe Telford -- played the police officer girlf...     her   \n",
       "\n",
       "   Pronoun-offset               A  A-offset  A-coref        B  B-offset  \\\n",
       "0             274  Cheryl Cassidy       191     True  Pauline       207   \n",
       "\n",
       "   B-coref                                                URL  \n",
       "0    False  http://en.wikipedia.org/wiki/List_of_Teachers_...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2000, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test-1</td>\n",
       "      <td>Upon their acceptance into the Kontinental Hoc...</td>\n",
       "      <td>His</td>\n",
       "      <td>383</td>\n",
       "      <td>Bob Suter</td>\n",
       "      <td>352</td>\n",
       "      <td>False</td>\n",
       "      <td>Dehner</td>\n",
       "      <td>366</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jeremy_Dehner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                               Text Pronoun  \\\n",
       "0  test-1  Upon their acceptance into the Kontinental Hoc...     His   \n",
       "\n",
       "   Pronoun-offset          A  A-offset  A-coref       B  B-offset  B-coref  \\\n",
       "0             383  Bob Suter       352    False  Dehner       366     True   \n",
       "\n",
       "                                          URL  \n",
       "0  http://en.wikipedia.org/wiki/Jeremy_Dehner  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2000, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>validation-1</td>\n",
       "      <td>He admitted making four trips to China and pla...</td>\n",
       "      <td>him</td>\n",
       "      <td>256</td>\n",
       "      <td>Jose de Venecia Jr</td>\n",
       "      <td>208</td>\n",
       "      <td>False</td>\n",
       "      <td>Abalos</td>\n",
       "      <td>241</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Commission_on_Ele...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               Text Pronoun  \\\n",
       "0  validation-1  He admitted making four trips to China and pla...     him   \n",
       "\n",
       "   Pronoun-offset                   A  A-offset  A-coref       B  B-offset  \\\n",
       "0             256  Jose de Venecia Jr       208    False  Abalos       241   \n",
       "\n",
       "   B-coref                                                URL  \n",
       "0    False  http://en.wikipedia.org/wiki/Commission_on_Ele...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(454, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.display_df(train_df)\n",
    "utils.display_df(test_df)\n",
    "utils.display_df(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifiy dataset\n",
    "data = valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data[\"Text\"]\n",
    "text.to_csv(data_interim_dir + \"input.txt\", index = False, header = False)\n",
    "\n",
    "extract_features_cmd = \"python {extract_features_script} \\\n",
    "  --input_file={input_file} \\\n",
    "  --output_file={output_file} \\\n",
    "  --vocab_file={vocab_file} \\\n",
    "  --bert_config_file={bert_config_file} \\\n",
    "  --init_checkpoint={init_checkpoint} \\\n",
    "  --layers=-1 \\\n",
    "  --max_seq_length=256 \\\n",
    "  --batch_size=8\".format(\n",
    "    extract_features_script = bert_dir + \"extract_features.py\",\n",
    "    input_file = data_interim_dir + \"input.txt\",\n",
    "    output_file = data_interim_dir + \"output.json\",\n",
    "    vocab_file = models_dir + \"uncased_L-12_H-768_A-12/vocab.txt\",\n",
    "    bert_config_file = models_dir + \"uncased_L-12_H-768_A-12/bert_config.json\",\n",
    "    init_checkpoint = models_dir + \"uncased_L-12_H-768_A-12/bert_model.ckpt\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python /Users/aarontrefler_temp2/Documents/My_Documents/Kaggle/kaggle-gendered-pronoun/bert/extract_features.py   --input_file=/Users/aarontrefler_temp2/Documents/My_Documents/Kaggle/kaggle-gendered-pronoun/data/interim/input.txt   --output_file=/Users/aarontrefler_temp2/Documents/My_Documents/Kaggle/kaggle-gendered-pronoun/data/interim/output.json   --vocab_file=/Users/aarontrefler_temp2/Documents/My_Documents/Kaggle/kaggle-gendered-pronoun/models/uncased_L-12_H-768_A-12/vocab.txt   --bert_config_file=/Users/aarontrefler_temp2/Documents/My_Documents/Kaggle/kaggle-gendered-pronoun/models/uncased_L-12_H-768_A-12/bert_config.json   --init_checkpoint=/Users/aarontrefler_temp2/Documents/My_Documents/Kaggle/kaggle-gendered-pronoun/models/uncased_L-12_H-768_A-12/bert_model.ckpt   --layers=-1   --max_seq_length=256   --batch_size=8'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute command in terminal\n",
    "extract_features_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_output = pd.read_json(data_interim_dir + \"output.json\", lines = True)\n",
    "\n",
    "index = data.index\n",
    "columns = [\"emb_A\", \"emb_B\", \"emb_P\", \"label\"]\n",
    "emb = pd.DataFrame(index = index, columns = columns)\n",
    "emb.index.name = \"ID\"\n",
    "    \n",
    "for i in range(len(data)): # For each line in the data file\n",
    "    # get the words A, B, Pronoun. Convert them to lower case, since we're using the uncased version of BERT\n",
    "    P = data.loc[i,\"Pronoun\"].lower()\n",
    "    A = data.loc[i,\"A\"].lower()\n",
    "    B = data.loc[i,\"B\"].lower()\n",
    "\n",
    "    # For each word, find the offset not counting spaces. This is necessary for comparison with the output of BERT\n",
    "    P_offset = data_utils.compute_offset_no_spaces(data.loc[i,\"Text\"], data.loc[i,\"Pronoun-offset\"])\n",
    "    A_offset = data_utils.compute_offset_no_spaces(data.loc[i,\"Text\"], data.loc[i,\"A-offset\"])\n",
    "    B_offset = data_utils.compute_offset_no_spaces(data.loc[i,\"Text\"], data.loc[i,\"B-offset\"])\n",
    "    # Figure out the length of A, B, not counting spaces or special characters\n",
    "    A_length = count_length_no_special(A)\n",
    "    B_length = count_length_no_special(B)\n",
    "\n",
    "    # Initialize embeddings with zeros\n",
    "    emb_A = np.zeros(768)\n",
    "    emb_B = np.zeros(768)\n",
    "    emb_P = np.zeros(768)\n",
    "\n",
    "    # Initialize counts\n",
    "    count_chars = 0\n",
    "    cnt_A, cnt_B, cnt_P = 0, 0, 0\n",
    "\n",
    "    features = pd.DataFrame(bert_output.loc[i,\"features\"]) # Get the BERT embeddings for the current line in the data file\n",
    "    for j in range(2,len(features)):  # Iterate over the BERT tokens for the current line; we skip over the first 2 tokens, which don't correspond to words\n",
    "        token = features.loc[j,\"token\"]\n",
    "\n",
    "        # See if the character count until the current token matches the offset of any of the 3 target words\n",
    "        if count_chars  == P_offset: \n",
    "            # print(token)\n",
    "            emb_P += np.array(features.loc[j,\"layers\"][0]['values'])\n",
    "            cnt_P += 1\n",
    "        if count_chars in range(A_offset, A_offset + A_length): \n",
    "            # print(token)\n",
    "            emb_A += np.array(features.loc[j,\"layers\"][0]['values'])\n",
    "            cnt_A +=1\n",
    "        if count_chars in range(B_offset, B_offset + B_length): \n",
    "            # print(token)\n",
    "            emb_B += np.array(features.loc[j,\"layers\"][0]['values'])\n",
    "            cnt_B +=1                               \n",
    "        # Update the character count\n",
    "        count_chars += count_length_no_special(token)\n",
    "    # Taking the average between tokens in the span of A or B, so divide the current value by the count \n",
    "    emb_A /= cnt_A\n",
    "    emb_B /= cnt_B\n",
    "\n",
    "    # Work out the label of the current piece of text\n",
    "    label = \"Neither\"\n",
    "    if (data.loc[i,\"A-coref\"] == True):\n",
    "        label = \"A\"\n",
    "    if (data.loc[i,\"B-coref\"] == True):\n",
    "        label = \"B\"\n",
    "\n",
    "    # Put everything together in emb\n",
    "    emb.iloc[i] = [emb_A, emb_B, emb_P, label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb_A</th>\n",
       "      <th>emb_B</th>\n",
       "      <th>emb_P</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.022817833333333315, -0.4209143333333332, 0....</td>\n",
       "      <td>[-0.3670055, -0.4148985, 0.5928515, 0.31750449...</td>\n",
       "      <td>[-0.123571, -0.16237000000000001, 0.040803, -0...</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.49702399999999997, -0.457437, 0.176571, -0...</td>\n",
       "      <td>[-0.862622, 0.055244999999999995, 0.7887909999...</td>\n",
       "      <td>[-0.035507, -0.293537, -0.376274, -0.156367, 1...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.067909, -0.3523786666666666, 0.296469, -0.4...</td>\n",
       "      <td>[0.975849, -1.198573, 0.427452, 0.289501, 0.73...</td>\n",
       "      <td>[-0.084656, -0.338914, 0.096026, -0.269828, 0....</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.06080499999999999, -0.21616800000000003, 0....</td>\n",
       "      <td>[-0.49502033333333334, -0.056551999999999984, ...</td>\n",
       "      <td>[-0.044270000000000004, 0.393868, 0.5250009999...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.009341999999999998, -0.13718666666666665, ...</td>\n",
       "      <td>[0.16866633333333333, -0.7929363333333334, 0.1...</td>\n",
       "      <td>[-0.393549, -0.395325, 0.112192, -0.1078519999...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                emb_A  \\\n",
       "ID                                                      \n",
       "0   [0.022817833333333315, -0.4209143333333332, 0....   \n",
       "1   [-0.49702399999999997, -0.457437, 0.176571, -0...   \n",
       "2   [0.067909, -0.3523786666666666, 0.296469, -0.4...   \n",
       "3   [0.06080499999999999, -0.21616800000000003, 0....   \n",
       "4   [-0.009341999999999998, -0.13718666666666665, ...   \n",
       "\n",
       "                                                emb_B  \\\n",
       "ID                                                      \n",
       "0   [-0.3670055, -0.4148985, 0.5928515, 0.31750449...   \n",
       "1   [-0.862622, 0.055244999999999995, 0.7887909999...   \n",
       "2   [0.975849, -1.198573, 0.427452, 0.289501, 0.73...   \n",
       "3   [-0.49502033333333334, -0.056551999999999984, ...   \n",
       "4   [0.16866633333333333, -0.7929363333333334, 0.1...   \n",
       "\n",
       "                                                emb_P    label  \n",
       "ID                                                              \n",
       "0   [-0.123571, -0.16237000000000001, 0.040803, -0...  Neither  \n",
       "1   [-0.035507, -0.293537, -0.376274, -0.156367, 1...        B  \n",
       "2   [-0.084656, -0.338914, 0.096026, -0.269828, 0....        B  \n",
       "3   [-0.044270000000000004, 0.393868, 0.5250009999...        A  \n",
       "4   [-0.393549, -0.395325, 0.112192, -0.1078519999...        B  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
